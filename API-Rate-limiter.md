### **Rate Limiting Algorithms Explained**  
Rate limiting is a technique used to **control the rate of incoming requests** to an API or service to prevent overuse, abuse, or system overload. Several algorithms are used for rate limiting:  

---

## **1ï¸âƒ£ Token Bucket Algorithm**  
ğŸ”¹ **Concept:**  
- A bucket holds a fixed number of tokens.  
- Each request **requires a token** to proceed.  
- Tokens are **added at a constant rate** (e.g., 10 tokens per second).  
- If no tokens are available, the request is **denied**.  

ğŸ”¹ **Example:**  
- Suppose the bucket size is **10 tokens** and **replenishes 1 token per second**.  
- A user can make **up to 10 requests instantly**, then needs to wait for new tokens.  

ğŸ”¹ **Use Case:**  
âœ… Good for **bursty traffic** because it allows requests to be made in quick succession until tokens run out.  

---

## **2ï¸âƒ£ Leaky Bucket Algorithm**  
ğŸ”¹ **Concept:**  
- Requests enter a **bucket** (queue).  
- The bucket **leaks (processes) requests at a constant rate**.  
- If the bucket is **full**, new requests are **dropped**.  

ğŸ”¹ **Example:**  
- If a system processes **5 requests per second**, but a user sends **100 requests instantly**, only **5 requests per second** will be processed, and extra requests **will be delayed or dropped**.  

ğŸ”¹ **Use Case:**  
âœ… Ensures a **steady request rate** and prevents **bursts of traffic** from overwhelming the system.  

---

## **3ï¸âƒ£ Sliding Log Algorithm**  
ğŸ”¹ **Concept:**  
- Stores a **timestamp** for each request in a **log**.  
- When a new request arrives, the system **removes outdated timestamps** beyond the time window and counts the remaining ones.  
- If the request count exceeds the limit, itâ€™s **denied**.  

ğŸ”¹ **Example:**  
- If a user is limited to **100 requests per minute**, the system checks the last **60 seconds** of logs.  
- If fewer than 100 requests exist, the new request is **allowed**.  

ğŸ”¹ **Use Case:**  
âœ… Provides **precise** rate limiting but requires more memory for storing logs.  

---

## **4ï¸âƒ£ Sliding Window Counter Algorithm**  
ğŸ”¹ **Concept:**  
- Divides time into **fixed windows** (e.g., 1-minute windows).  
- Counts requests in the **current and previous window** with a **weighted average** to smooth transitions.  

ğŸ”¹ **Example:**  
- If the limit is **100 requests per minute**, but a request comes at **59 seconds**, the system considers a fraction of the previous windowâ€™s count.  

ğŸ”¹ **Use Case:**  
âœ… Reduces **abrupt cutoffs** seen in fixed window counters while keeping efficiency.  

---

## **5ï¸âƒ£ Race Conditions in Distributed Systems**  
When **rate limiting is implemented across multiple servers**, race conditions can occur due to **inconsistent counters**. Solutions include:  
âœ” **Centralized rate limiter** (single Redis instance).  
âœ” **Consistent hashing** (assign requests to the same node).  
âœ” **Distributed locks** (prevent race conditions).  

---

### **Comparison Table**
| Algorithm | Handles Bursts? | Memory Usage | Complexity | Use Case |
|-----------|---------------|--------------|------------|----------|
| **Token Bucket** | âœ… Yes | Low | Medium | Allows bursts, smooths traffic |
| **Leaky Bucket** | âŒ No | Low | Low | Smooth traffic flow |
| **Sliding Logs** | âœ… Yes | High | High | Precise tracking |
| **Sliding Window Counter** | âœ… Yes | Medium | Medium | Balanced approach |

Would you like **code examples** for any of these? ğŸš€
